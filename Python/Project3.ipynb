{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSIoWWri5zP2W/4wi9/BLT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyns417/Aiffel_quest_cr2/blob/master/Python/Project3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) 손글씨를 분류하기"
      ],
      "metadata": {
        "id": "Z0geKPfhWhif"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLjZwt7GWRMe",
        "outputId": "91beab67-a15f-46d4-baaf-bbbf840033f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decision tree 로 modeling 한 결과 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        43\n",
            "           1       0.81      0.81      0.81        42\n",
            "           2       0.79      0.82      0.80        40\n",
            "           3       0.79      0.91      0.85        34\n",
            "           4       0.83      0.95      0.89        37\n",
            "           5       0.90      0.96      0.93        28\n",
            "           6       0.84      0.93      0.88        28\n",
            "           7       0.96      0.82      0.89        33\n",
            "           8       0.88      0.65      0.75        43\n",
            "           9       0.78      0.78      0.78        32\n",
            "\n",
            "    accuracy                           0.86       360\n",
            "   macro avg       0.86      0.86      0.86       360\n",
            "weighted avg       0.86      0.86      0.85       360\n",
            "\n",
            "SVM 으로 modeling 한 결과 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        43\n",
            "           1       0.95      1.00      0.98        42\n",
            "           2       1.00      1.00      1.00        40\n",
            "           3       1.00      1.00      1.00        34\n",
            "           4       1.00      1.00      1.00        37\n",
            "           5       0.93      1.00      0.97        28\n",
            "           6       1.00      1.00      1.00        28\n",
            "           7       1.00      1.00      1.00        33\n",
            "           8       1.00      0.93      0.96        43\n",
            "           9       1.00      0.97      0.98        32\n",
            "\n",
            "    accuracy                           0.99       360\n",
            "   macro avg       0.99      0.99      0.99       360\n",
            "weighted avg       0.99      0.99      0.99       360\n",
            "\n",
            "SGDClassifier 로 modeling 한 결과 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        43\n",
            "           1       0.87      0.95      0.91        42\n",
            "           2       0.98      1.00      0.99        40\n",
            "           3       1.00      0.88      0.94        34\n",
            "           4       0.97      0.97      0.97        37\n",
            "           5       0.85      1.00      0.92        28\n",
            "           6       0.93      0.93      0.93        28\n",
            "           7       0.94      0.97      0.96        33\n",
            "           8       0.95      0.81      0.88        43\n",
            "           9       0.90      0.88      0.89        32\n",
            "\n",
            "    accuracy                           0.94       360\n",
            "   macro avg       0.94      0.94      0.94       360\n",
            "weighted avg       0.94      0.94      0.94       360\n",
            "\n",
            "Logistic regression으로 modeling 한 결과 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        43\n",
            "           1       0.95      0.95      0.95        42\n",
            "           2       0.98      1.00      0.99        40\n",
            "           3       0.94      0.97      0.96        34\n",
            "           4       0.97      1.00      0.99        37\n",
            "           5       0.82      0.96      0.89        28\n",
            "           6       1.00      0.96      0.98        28\n",
            "           7       0.97      0.97      0.97        33\n",
            "           8       0.92      0.81      0.86        43\n",
            "           9       0.97      0.91      0.94        32\n",
            "\n",
            "    accuracy                           0.95       360\n",
            "   macro avg       0.95      0.95      0.95       360\n",
            "weighted avg       0.95      0.95      0.95       360\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "digits=load_digits()\n",
        "# digits.keys() dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n",
        "# digits.target_names\n",
        "\n",
        "digit_data=digits.data\n",
        "digit_label=digits.target\n",
        "X_train, X_test, y_train, y_test=train_test_split(digit_data, digit_label, test_size=0.2, random_state=7)\n",
        "\n",
        "# decision tree\n",
        "decision_tree=DecisionTreeClassifier(random_state=32)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred=decision_tree.predict(X_test)\n",
        "print(\"decision tree 로 modeling 한 결과 : \")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# svm\n",
        "svm_model=svm.SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred=svm_model.predict(X_test)\n",
        "print(\"SVM 으로 modeling 한 결과 : \")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# sgd\n",
        "sgd_model=SGDClassifier()\n",
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred=sgd_model.predict(X_test)\n",
        "print(\"SGDClassifier 로 modeling 한 결과 : \")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# logistic regression\n",
        "logistic_model=LogisticRegression()\n",
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred=logistic_model.predict(X_test)\n",
        "print(\"Logistic regression으로 modeling 한 결과 : \")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "선택한 모델 : SVM\n",
        "accuracy 가 제일 높은 것은 SVM model 이며, 각 label 마다 precision 과 recall 모두 다른 모델에 비해서 높은 편이었다"
      ],
      "metadata": {
        "id": "aLFpeemMZW68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2) 와인 분류하기"
      ],
      "metadata": {
        "id": "9Bp0cGfXZrrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "wine=load_wine()\n",
        "wine.keys()\n",
        "wine.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpQw9PhkZseZ",
        "outputId": "197bf030-45b0-4fde-a808-686099d5a0b8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine_data=wine.data\n",
        "wine_label=wine.target\n",
        "X_train, X_test, y_train, y_test=train_test_split(wine_data, wine_label, test_size=0.2, random_state=7)\n"
      ],
      "metadata": {
        "id": "fv-YCFu5aKt6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decision tree\n",
        "decision_tree=DecisionTreeClassifier(random_state=32)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred=decision_tree.predict(X_test)\n",
        "print(\"decision tree 로 modeling 한 결과 : \")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# svm\n",
        "svm_model=svm.SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred=svm_model.predict(X_test)\n",
        "print(\"SVM 으로 modeling 한 결과 : \")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# sgd\n",
        "sgd_model=SGDClassifier()\n",
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred=sgd_model.predict(X_test)\n",
        "print(\"SGDClassifier 로 modeling 한 결과 : \")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# logistic regression\n",
        "logistic_model=LogisticRegression()\n",
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred=logistic_model.predict(X_test)\n",
        "print(\"Logistic regression으로 modeling 한 결과 : \")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vck9H_paZ5P",
        "outputId": "b79c9222-8868-41ca-aff8-82f010566765"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decision tree 로 modeling 한 결과 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.89      1.00      0.94        17\n",
            "           2       1.00      0.83      0.91        12\n",
            "\n",
            "    accuracy                           0.94        36\n",
            "   macro avg       0.96      0.94      0.95        36\n",
            "weighted avg       0.95      0.94      0.94        36\n",
            "\n",
            "SVM 으로 modeling 한 결과 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86         7\n",
            "           1       0.58      0.88      0.70        17\n",
            "           2       0.33      0.08      0.13        12\n",
            "\n",
            "    accuracy                           0.61        36\n",
            "   macro avg       0.59      0.61      0.56        36\n",
            "weighted avg       0.55      0.61      0.54        36\n",
            "\n",
            "SGDClassifier 로 modeling 한 결과 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      1.00      0.82         7\n",
            "           1       0.86      0.71      0.77        17\n",
            "           2       0.67      0.67      0.67        12\n",
            "\n",
            "    accuracy                           0.75        36\n",
            "   macro avg       0.74      0.79      0.75        36\n",
            "weighted avg       0.76      0.75      0.75        36\n",
            "\n",
            "Logistic regression으로 modeling 한 결과 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.86      0.92         7\n",
            "           1       0.94      1.00      0.97        17\n",
            "           2       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.98      0.95      0.96        36\n",
            "weighted avg       0.97      0.97      0.97        36\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "선택한 model: Logistic regression\n",
        "이유: accuracy 가 높은 것 중에 하나였고, classification 별로 구분해서 봤을 때도 대부분이 precision 및 recall 이 높은 편이었다"
      ],
      "metadata": {
        "id": "ZcnNB--MakRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) 유방암 여부 진단"
      ],
      "metadata": {
        "id": "zIeASKwIa5Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "brst=load_breast_cancer()\n",
        "#brst.keys()\n",
        "brst.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNF8j0pia8U_",
        "outputId": "1a35fd5c-8bba-4002-f7f4-0816a16c7ec6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['malignant', 'benign'], dtype='<U9')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "brst_data=brst.data\n",
        "brst_label=brst.target\n",
        "X_train, X_test, y_train, y_test=train_test_split(brst_data, brst_label, test_size=0.2, random_state=7)\n"
      ],
      "metadata": {
        "id": "d3vywEpabMYM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decision tree\n",
        "decision_tree=DecisionTreeClassifier(random_state=32)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred=decision_tree.predict(X_test)\n",
        "print(\"decision tree 로 modeling 한 결과 : \")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "# svm\n",
        "svm_model=svm.SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred=svm_model.predict(X_test)\n",
        "print(\"SVM 으로 modeling 한 결과 : \")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "# sgd\n",
        "sgd_model=SGDClassifier()\n",
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred=sgd_model.predict(X_test)\n",
        "print(\"SGDClassifier 로 modeling 한 결과 : \")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "# logistic regression\n",
        "logistic_model=LogisticRegression()\n",
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred=logistic_model.predict(X_test)\n",
        "print(\"Logistic regression으로 modeling 한 결과 : \")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEF80N5LbY8-",
        "outputId": "de209962-982e-4f05-80af-1f7578bbc73c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decision tree 로 modeling 한 결과 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.82      0.87        40\n",
            "           1       0.91      0.96      0.93        74\n",
            "\n",
            "    accuracy                           0.91       114\n",
            "   macro avg       0.91      0.89      0.90       114\n",
            "weighted avg       0.91      0.91      0.91       114\n",
            "\n",
            "[[33  7]\n",
            " [ 3 71]]\n",
            "SVM 으로 modeling 한 결과 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.72      0.84        40\n",
            "           1       0.87      1.00      0.93        74\n",
            "\n",
            "    accuracy                           0.90       114\n",
            "   macro avg       0.94      0.86      0.89       114\n",
            "weighted avg       0.92      0.90      0.90       114\n",
            "\n",
            "[[29 11]\n",
            " [ 0 74]]\n",
            "SGDClassifier 로 modeling 한 결과 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.70      0.82        40\n",
            "           1       0.86      1.00      0.92        74\n",
            "\n",
            "    accuracy                           0.89       114\n",
            "   macro avg       0.93      0.85      0.87       114\n",
            "weighted avg       0.91      0.89      0.89       114\n",
            "\n",
            "[[28 12]\n",
            " [ 0 74]]\n",
            "Logistic regression으로 modeling 한 결과 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.82      0.90        40\n",
            "           1       0.91      1.00      0.95        74\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.96      0.91      0.93       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n",
            "[[33  7]\n",
            " [ 0 74]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "선택한 모델: Logistic regression\n",
        "악성 암을 확인하는 모델이기 때문에 sensitivity 가 큰 모델을 골라야한다"
      ],
      "metadata": {
        "id": "SyY-HmDIbdgX"
      }
    }
  ]
}